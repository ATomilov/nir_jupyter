{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.12.0\n",
      "Keras version: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Keras version:', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import re\n",
    "import datetime\n",
    "import cairocffi as cairo\n",
    "import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max plate length in \"anpr_ocr__train\": 8\n",
      "Max plate length in \"anpr_ocr__train\": 8\n",
      "Letters in train and val do match\n",
      "Length of train letters = 22\n",
      "Length of validation letters = 22\n",
      "Letters: 0 1 2 3 4 5 6 7 8 9 A B C E H K M O P T X Y\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# print(os.path.basename('/home/apofeo/supervisely-tutorials/anpr'))\n",
    "def get_counter(dirpath, tag):\n",
    "    dirname = os.path.basename(dirpath)\n",
    "    ann_dirpath = join(dirpath, 'ann')\n",
    "    letters = ''\n",
    "    lens = []\n",
    "    for filename in os.listdir(ann_dirpath):\n",
    "        json_filepath = join(ann_dirpath, filename)\n",
    "        ann = json.load(open(json_filepath, 'r'))\n",
    "        tags = ann['tags']\n",
    "        if tag in tags:\n",
    "            description = ann['description']\n",
    "            lens.append(len(description))\n",
    "            letters += description\n",
    "    print('Max plate length in \"%s\":' % dirname, max(Counter(lens).keys()))\n",
    "    return Counter(letters)\n",
    "c_val = get_counter('def_base/anpr_ocr/anpr_ocr__train', 'val')\n",
    "c_train = get_counter('def_base/anpr_ocr/anpr_ocr__train', 'train')\n",
    "# c_val = get_counter('anpr/data/anpr_ocr/anpr_ocr__train', 'val')\n",
    "# c_train = get_counter('anpr/data/anpr_ocr/anpr_ocr__train', 'train')\n",
    "letters_train = set(c_train.keys())\n",
    "letters_val = set(c_val.keys())\n",
    "if letters_train == letters_val:\n",
    "    print('Letters in train and val do match') \n",
    "else:\n",
    "    raise Exception()\n",
    "print('Length of train letters = %d\\nLength of validation letters = %d' % (len(letters_train), len(letters_val)))\n",
    "letters = sorted(list(letters_train))\n",
    "print('Letters:', ' '.join(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_text(labels):\n",
    "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: letters.index(x), text))\n",
    "\n",
    "def is_valid_str(s):\n",
    "    for ch in s:\n",
    "        if not ch in letters:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class TextImageGenerator:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dirpath,\n",
    "                 tag,\n",
    "                 img_w, img_h, \n",
    "                 batch_size, \n",
    "                 downsample_factor,\n",
    "                 max_text_len=8):\n",
    "        \n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.batch_size = batch_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.downsample_factor = downsample_factor\n",
    "        \n",
    "        img_dirpath = join(dirpath, 'img')\n",
    "        ann_dirpath = join(dirpath, 'ann')\n",
    "        self.samples = []\n",
    "        for filename in os.listdir(img_dirpath):\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            if ext in ['.png', '.jpg']:\n",
    "                img_filepath = join(img_dirpath, filename)\n",
    "                json_filepath = join(ann_dirpath, name + '.json')\n",
    "                ann = json.load(open(json_filepath, 'r'))\n",
    "                description = ann['description']\n",
    "                tags = ann['tags']\n",
    "                if tag not in tags:\n",
    "                    continue\n",
    "                if is_valid_str(description):\n",
    "                    self.samples.append([img_filepath, description])\n",
    "        \n",
    "        self.n = len(self.samples)\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        \n",
    "    def build_data(self):\n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
    "        self.texts = []\n",
    "        for i, (img_filepath, text) in enumerate(self.samples):\n",
    "            img = cv2.imread(img_filepath)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
    "            img = img.astype(np.float32)\n",
    "            img /= 255\n",
    "            # width and height are backwards from typical Keras convention\n",
    "            # because width is the time dimension when it gets fed into the RNN\n",
    "            self.imgs[i, :, :] = img\n",
    "            self.texts.append(text)\n",
    "        \n",
    "    def get_output_size(self):\n",
    "        return len(letters) + 1\n",
    "    \n",
    "    def next_sample(self):\n",
    "        self.cur_index += 1\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
    "    \n",
    "    def next_batch(self):\n",
    "        while True:\n",
    "            # width and height are backwards from typical Keras convention\n",
    "            # because width is the time dimension when it gets fed into the RNN\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                X_data = np.ones([self.batch_size, 1, self.img_w, self.img_h])\n",
    "            else:\n",
    "                X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])\n",
    "            Y_data = np.ones([self.batch_size, self.max_text_len])\n",
    "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)\n",
    "            label_length = np.zeros((self.batch_size, 1))\n",
    "            source_str = []\n",
    "                                   \n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_sample()\n",
    "                img = img.T\n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    img = np.expand_dims(img, 0)\n",
    "                else:\n",
    "                    img = np.expand_dims(img, -1)\n",
    "                X_data[i] = img\n",
    "                \n",
    "#                 labels = text_to_labels(text)\n",
    "#                 Y_data[i, 0:len(labels)] = labels\n",
    "                \n",
    "                Y_data[i] = text_to_labels(text)\n",
    "                source_str.append(text)\n",
    "                label_length[i] = len(text)\n",
    "                \n",
    "            inputs = {\n",
    "                'the_input': X_data,\n",
    "                'the_labels': Y_data,\n",
    "                'input_length': input_length,\n",
    "                'label_length': label_length,\n",
    "                #'source_str': source_str\n",
    "            }\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "            yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiger = TextImageGenerator('def_base/anpr_ocr/anpr_ocr__train', 'val', 128, 64, 8, 4)\n",
    "# tiger = TextImageGenerator('anpr/data/anpr_ocr/anpr_ocr__train', 'val', 128, 64, 4, 4)\n",
    "tiger.build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generator output (data which will be fed into the neutral network):\n",
      "1) the_input (image)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) the_labels (plate number): H140HE83 is encoded as [14, 1, 4, 0, 14, 13, 8, 3]\n",
      "3) input_length (width of image that is fed to the loss function): 30 == 128 / 4 - 2\n",
      "4) label_length (length of plate number): 8\n"
     ]
    }
   ],
   "source": [
    "for inp, out in tiger.next_batch():\n",
    "    print('Text generator output (data which will be fed into the neutral network):')\n",
    "    print('1) the_input (image)')\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        img = inp['the_input'][0, 0, :, :]\n",
    "    else:\n",
    "        img = inp['the_input'][0, :, :, 0]\n",
    "    \n",
    "    plt.imshow(img.T, cmap='gray')\n",
    "    plt.show()\n",
    "    print('2) the_labels (plate number): %s is encoded as %s' % \n",
    "          (labels_to_text(inp['the_labels'][0]), list(map(int, inp['the_labels'][0]))))\n",
    "    print('3) input_length (width of image that is fed to the loss function): %d == %d / 4 - 2' % \n",
    "          (inp['input_length'][0], tiger.img_w))\n",
    "    print('4) label_length (length of plate number): %d' % inp['label_length'][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def train(img_w, load=False):\n",
    "    # Input Parameters\n",
    "    img_h = 64\n",
    "\n",
    "    # Network parameters\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "        \n",
    "    batch_size = 32\n",
    "    downsample_factor = pool_size ** 2\n",
    "    tiger_train = TextImageGenerator('def_base/anpr_ocr/anpr_ocr__train', 'train', img_w, img_h, batch_size, downsample_factor)\n",
    "    tiger_train.build_data()\n",
    "    tiger_val = TextImageGenerator('def_base/anpr_ocr/anpr_ocr__train', 'val', img_w, img_h, batch_size, downsample_factor)\n",
    "    tiger_val.build_data()\n",
    "\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv1')(input_data)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv2')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "    # Two layers of bidirecitonal GRUs\n",
    "    # GRU seems to work as well, if not better than LSTM:\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(tiger_train.get_output_size(), kernel_initializer='he_normal',\n",
    "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[tiger_train.max_text_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "    if load:\n",
    "        model = load_model('./tmp_model.h5', compile=False)\n",
    "    else:\n",
    "        model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    \n",
    "    if not load:\n",
    "        # captures output of softmax so we can decode the output during visualization\n",
    "        test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "        model.fit_generator(generator=tiger_train.next_batch(), \n",
    "                            steps_per_epoch=tiger_train.n,\n",
    "                            epochs=1, \n",
    "                            validation_data=tiger_val.next_batch(), \n",
    "                            validation_steps=tiger_val.n)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 32, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32, 23)       23575       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 32, 23)       0           dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,857,319\n",
      "Trainable params: 4,857,319\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1\n",
      "   71/10796 [..............................] - ETA: 3:24:43 - loss: 40.9378"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-308b3208bb84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-59c774c4353d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(img_w, load)\u001b[0m\n\u001b[1;32m     87\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtiger_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                             validation_steps=tiger_val.n)\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train(128, load=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
