{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.12.0\n",
      "Keras version: 2.2.4\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7625265691400161561\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6788138323356833988\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Keras version:', keras.__version__)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "# tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import re\n",
    "import datetime\n",
    "import cairocffi as cairo\n",
    "import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max plate length in \"anpr_ocr__train\": 8\n",
      "Max plate length in \"anpr_ocr__train\": 8\n",
      "Letters in train and val do match\n",
      "Length of train letters = 22\n",
      "Length of validation letters = 22\n",
      "Letters: 0 1 2 3 4 5 6 7 8 9 A B C E H K M O P T X Y\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# print(os.path.basename('/home/apofeo/supervisely-tutorials/anpr'))\n",
    "def get_counter(dirpath, tag):\n",
    "    dirname = os.path.basename(dirpath)\n",
    "    ann_dirpath = join(dirpath, 'ann')\n",
    "    letters = ''\n",
    "    lens = []\n",
    "    for filename in os.listdir(ann_dirpath):\n",
    "        json_filepath = join(ann_dirpath, filename)\n",
    "        ann = json.load(open(json_filepath, 'r'))\n",
    "        tags = ann['tags']\n",
    "        if tag in tags:\n",
    "            description = ann['description']\n",
    "            lens.append(len(description))\n",
    "            letters += description\n",
    "    print('Max plate length in \"%s\":' % dirname, max(Counter(lens).keys()))\n",
    "    return Counter(letters)\n",
    "c_val = get_counter('def_base/anpr_ocr/anpr_ocr__train', 'val')\n",
    "c_train = get_counter('def_base/anpr_ocr/anpr_ocr__train', 'train')\n",
    "# c_val = get_counter('anpr/data/anpr_ocr/anpr_ocr__train', 'val')\n",
    "# c_train = get_counter('anpr/data/anpr_ocr/anpr_ocr__train', 'train')\n",
    "letters_train = set(c_train.keys())\n",
    "letters_val = set(c_val.keys())\n",
    "if letters_train == letters_val:\n",
    "    print('Letters in train and val do match') \n",
    "else:\n",
    "    raise Exception()\n",
    "print('Length of train letters = %d\\nLength of validation letters = %d' % (len(letters_train), len(letters_val)))\n",
    "letters = sorted(list(letters_train))\n",
    "print('Letters:', ' '.join(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_text(labels):\n",
    "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: letters.index(x), text))\n",
    "\n",
    "def is_valid_str(s):\n",
    "    for ch in s:\n",
    "        if not ch in letters:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class TextImageGenerator:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dirpath,\n",
    "                 tag,\n",
    "                 img_w, img_h, \n",
    "                 batch_size, \n",
    "                 downsample_factor,\n",
    "                 max_text_len=8):\n",
    "        \n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.batch_size = batch_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.downsample_factor = downsample_factor\n",
    "        \n",
    "        img_dirpath = join(dirpath, 'img')\n",
    "        ann_dirpath = join(dirpath, 'ann')\n",
    "        self.samples = []\n",
    "        for filename in os.listdir(img_dirpath):\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            if ext in ['.png', '.jpg']:\n",
    "                img_filepath = join(img_dirpath, filename)\n",
    "                json_filepath = join(ann_dirpath, name + '.json')\n",
    "                ann = json.load(open(json_filepath, 'r'))\n",
    "                description = ann['description']\n",
    "                tags = ann['tags']\n",
    "                if tag not in tags:\n",
    "                    continue\n",
    "                if is_valid_str(description):\n",
    "                    self.samples.append([img_filepath, description])\n",
    "        \n",
    "        self.n = len(self.samples)\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        \n",
    "    def build_data(self):\n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
    "        self.texts = []\n",
    "        for i, (img_filepath, text) in enumerate(self.samples):\n",
    "            img = cv2.imread(img_filepath)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
    "            img = img.astype(np.float32)\n",
    "            img /= 255\n",
    "            # width and height are backwards from typical Keras convention\n",
    "            # because width is the time dimension when it gets fed into the RNN\n",
    "            self.imgs[i, :, :] = img\n",
    "            self.texts.append(text)\n",
    "        \n",
    "    def get_output_size(self):\n",
    "        return len(letters) + 1\n",
    "    \n",
    "    def next_sample(self):\n",
    "        self.cur_index += 1\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
    "    \n",
    "    def next_batch(self):\n",
    "        while True:\n",
    "            # width and height are backwards from typical Keras convention\n",
    "            # because width is the time dimension when it gets fed into the RNN\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                X_data = np.ones([self.batch_size, 1, self.img_w, self.img_h])\n",
    "            else:\n",
    "                X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])\n",
    "            Y_data = np.ones([self.batch_size, self.max_text_len])\n",
    "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)\n",
    "            label_length = np.zeros((self.batch_size, 1))\n",
    "            source_str = []\n",
    "                                   \n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_sample()\n",
    "                img = img.T\n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    img = np.expand_dims(img, 0)\n",
    "                else:\n",
    "                    img = np.expand_dims(img, -1)\n",
    "                X_data[i] = img\n",
    "                \n",
    "#                 labels = text_to_labels(text)\n",
    "#                 Y_data[i, 0:len(labels)] = labels\n",
    "                \n",
    "                Y_data[i] = text_to_labels(text)\n",
    "                source_str.append(text)\n",
    "                label_length[i] = len(text)\n",
    "                \n",
    "            inputs = {\n",
    "                'the_input': X_data,\n",
    "                'the_labels': Y_data,\n",
    "                'input_length': input_length,\n",
    "                'label_length': label_length,\n",
    "                #'source_str': source_str\n",
    "            }\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "            yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiger = TextImageGenerator('def_base/anpr_ocr/anpr_ocr__train', 'val', 128, 64, 8, 4)\n",
    "# tiger = TextImageGenerator('anpr/data/anpr_ocr/anpr_ocr__train', 'val', 128, 64, 4, 4)\n",
    "tiger.build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generator output (data which will be fed into the neutral network):\n",
      "1) the_input (image)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) the_labels (plate number): B261MT98 is encoded as [11, 2, 6, 1, 16, 19, 9, 8]\n",
      "3) input_length (width of image that is fed to the loss function): 30 == 128 / 4 - 2\n",
      "4) label_length (length of plate number): 8\n"
     ]
    }
   ],
   "source": [
    "for inp, out in tiger.next_batch():\n",
    "    print('Text generator output (data which will be fed into the neutral network):')\n",
    "    print('1) the_input (image)')\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        img = inp['the_input'][0, 0, :, :]\n",
    "    else:\n",
    "        img = inp['the_input'][0, :, :, 0]\n",
    "    \n",
    "    plt.imshow(img.T, cmap='gray')\n",
    "    plt.show()\n",
    "    print('2) the_labels (plate number): %s is encoded as %s' % \n",
    "          (labels_to_text(inp['the_labels'][0]), list(map(int, inp['the_labels'][0]))))\n",
    "    print('3) input_length (width of image that is fed to the loss function): %d == %d / 4 - 2' % \n",
    "          (inp['input_length'][0], tiger.img_w))\n",
    "    print('4) label_length (length of plate number): %d' % inp['label_length'][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def train(img_w, load=False):\n",
    "    # Input Parameters\n",
    "    img_h = 64\n",
    "\n",
    "    # Network parameters\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "        \n",
    "    batch_size = 32\n",
    "    downsample_factor = pool_size ** 2\n",
    "    tiger_train = TextImageGenerator('def_base/anpr_ocr/anpr_ocr__train', 'train', img_w, img_h, batch_size, downsample_factor)\n",
    "    tiger_train.build_data()\n",
    "    tiger_val = TextImageGenerator('def_base/anpr_ocr/anpr_ocr__train', 'val', img_w, img_h, batch_size, downsample_factor)\n",
    "    tiger_val.build_data()\n",
    "\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv1')(input_data)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv2')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "    # Two layers of bidirecitonal GRUs\n",
    "    # GRU seems to work as well, if not better than LSTM:\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(tiger_train.get_output_size(), kernel_initializer='he_normal',\n",
    "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[tiger_train.max_text_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "    if load:\n",
    "        model = load_model('./tmp_model.h5', compile=False)\n",
    "    else:\n",
    "        model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    \n",
    "    if not load:\n",
    "        # captures output of softmax so we can decode the output during visualization\n",
    "        test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "        model.fit_generator(generator=tiger_train.next_batch(), \n",
    "                            steps_per_epoch=tiger_train.n,\n",
    "                            epochs=1, \n",
    "                            validation_data=tiger_val.next_batch(), \n",
    "                            validation_steps=tiger_val.n)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32, 512)      1574400     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 32, 512)      1574400     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32, 23)       23575       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 32, 23)       0           dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,857,319\n",
      "Trainable params: 4,857,319\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation conv1_1/truncated_normal/TruncatedNormal: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[node conv1_1/truncated_normal/TruncatedNormal (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185)  = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=8456166, _device=\"/device:GPU:0\"](conv1_1/truncated_normal/shape)]]\n\nCaused by op 'conv1_1/truncated_normal/TruncatedNormal', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-508eb812446a>\", line 2, in <module>\n    model = train(128, load=False)\n  File \"<ipython-input-12-59c774c4353d>\", line 36, in train\n    name='conv1')(input_data)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\", line 141, in build\n    constraint=self.kernel_constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\", line 249, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"/usr/local/lib/python3.6/dist-packages/keras/initializers.py\", line 214, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 4185, in truncated_normal\n    return tf.truncated_normal(shape, mean, stddev, dtype=dtype, seed=seed)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py\", line 175, in truncated_normal\n    shape_tensor, dtype, seed=seed1, seed2=seed2)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_random_ops.py\", line 909, in truncated_normal\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation conv1_1/truncated_normal/TruncatedNormal: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[node conv1_1/truncated_normal/TruncatedNormal (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185)  = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=8456166, _device=\"/device:GPU:0\"](conv1_1/truncated_normal/shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation conv1_1/truncated_normal/TruncatedNormal: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[{{node conv1_1/truncated_normal/TruncatedNormal}} = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=8456166, _device=\"/device:GPU:0\"](conv1_1/truncated_normal/shape)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-508eb812446a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/gpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-59c774c4353d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(img_w, load)\u001b[0m\n\u001b[1;32m     87\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtiger_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                             validation_steps=tiger_val.n)\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation conv1_1/truncated_normal/TruncatedNormal: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[node conv1_1/truncated_normal/TruncatedNormal (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185)  = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=8456166, _device=\"/device:GPU:0\"](conv1_1/truncated_normal/shape)]]\n\nCaused by op 'conv1_1/truncated_normal/TruncatedNormal', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/apofeo/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-508eb812446a>\", line 2, in <module>\n    model = train(128, load=False)\n  File \"<ipython-input-12-59c774c4353d>\", line 36, in train\n    name='conv1')(input_data)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\", line 141, in build\n    constraint=self.kernel_constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\", line 249, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"/usr/local/lib/python3.6/dist-packages/keras/initializers.py\", line 214, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 4185, in truncated_normal\n    return tf.truncated_normal(shape, mean, stddev, dtype=dtype, seed=seed)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py\", line 175, in truncated_normal\n    shape_tensor, dtype, seed=seed1, seed2=seed2)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_random_ops.py\", line 909, in truncated_normal\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation conv1_1/truncated_normal/TruncatedNormal: Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[node conv1_1/truncated_normal/TruncatedNormal (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185)  = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=8456166, _device=\"/device:GPU:0\"](conv1_1/truncated_normal/shape)]]\n"
     ]
    }
   ],
   "source": [
    "# with tf.device(\"/gpu:0\"):\n",
    "    model = train(128, load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
